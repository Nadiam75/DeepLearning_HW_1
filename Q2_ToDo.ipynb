{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpzaPwugLYzI"
   },
   "source": [
    "======================================================\n",
    "# **Deep Learning Course** - Fall 2021 -25647\n",
    "======================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15VGmzTSMRHP"
   },
   "source": [
    "======================================================\n",
    "### **Student Information:**\n",
    "* Name= Zahra\n",
    "* Last Name= Meskar\n",
    "* ID= 99206406\n",
    "\n",
    "======================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUuU85l7rg5P"
   },
   "source": [
    "# **Deep Crossentropy method**\n",
    "\n",
    "In this section we'll extend your CEM implementation with neural networks! You will train a multi-layer neural network to solve simple continuous state space games.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5m_7tNU0rg5Q",
    "outputId": "bb5dfdda-f94e-45fe-bd0a-c6b4ef793507"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting virtual X frame buffer: Xvfb.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
    "\n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/grading.py -O ../grading.py\n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/week1_intro/submit.py\n",
    "\n",
    "    !touch .setup_complete\n",
    "\n",
    "# This code creates a virtual display to draw game images on.\n",
    "# It will have no effect if your machine has a monitor.\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "    !bash ../xvfb start\n",
    "    os.environ['DISPLAY'] = ':1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "yp54Mdhsrg5S",
    "outputId": "60b2451e-68f0-4a48-96b2-3001ef9e2f9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state vector dim = 4\n",
      "n_actions = 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# if you see \"<classname> has no attribute .env\", remove .env or update gym\n",
    "env = gym.make(\"CartPole-v0\").env\n",
    "\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape[0]\n",
    "\n",
    "plt.imshow(env.render(\"rgb_array\"))\n",
    "print(\"state vector dim =\", state_dim)\n",
    "print(\"n_actions =\", n_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPxbTD5Org5S"
   },
   "source": [
    "# Neural Network Policy\n",
    "\n",
    "For this assignment we'll utilize the simplified neural network implementation from __[Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)__. Here's what you'll need:\n",
    "\n",
    "* `agent.partial_fit(states, actions)` - make a single training pass over the data. Maximize the probabilitity of :actions: from :states:\n",
    "* `agent.predict_proba(states)` - predict probabilities of all actions, a matrix of shape __[len(states), n_actions]__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CLVE-mQbrg5S"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "agent = MLPClassifier(\n",
    "    hidden_layer_sizes=(20, 20),\n",
    "    activation='tanh',\n",
    ")\n",
    "\n",
    "# initialize agent to the dimension of state space and number of actions\n",
    "agent.partial_fit([env.reset()] * n_actions, range(n_actions), range(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CSFzTNyKrg5S"
   },
   "outputs": [],
   "source": [
    "def generate_session(env, agent, t_max=1000):\n",
    "    \"\"\"\n",
    "    Play a single game using agent neural network.\n",
    "    Terminate when game finishes or after :t_max: steps\n",
    "    \"\"\"\n",
    "    states, actions = [], []\n",
    "    total_reward = 0\n",
    "\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "        \n",
    "        # use agent to predict a vector of action probabilities for state :s:\n",
    "        probs = <YOUR CODE>\n",
    "\n",
    "        assert probs.shape == (env.action_space.n,), \"make sure probabilities are a vector (hint: np.reshape)\"\n",
    "        \n",
    "        # use the probabilities you predicted to pick an action\n",
    "        # sample proportionally to the probabilities, don't just take the most likely action\n",
    "        a = <YOUR CODE>\n",
    "        # ^-- hint: try np.random.choice\n",
    "\n",
    "        new_s, r, done, info = env.step(a)\n",
    "\n",
    "        # record sessions like you did before\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        total_reward += r\n",
    "\n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "    return states, actions, total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1gIcetVTrg5T"
   },
   "outputs": [],
   "source": [
    "dummy_states, dummy_actions, dummy_reward = generate_session(env, agent, t_max=5)\n",
    "print(\"states:\", np.stack(dummy_states))\n",
    "print(\"actions:\", dummy_actions)\n",
    "print(\"reward:\", dummy_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peT2AiClrg5T"
   },
   "source": [
    "### CEM steps\n",
    "Deep CEM uses exactly the same strategy as the regular CEM.\n",
    "\n",
    "The only difference is that now each observation is not a number but a `float32` vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZBccx26Jrg5U"
   },
   "outputs": [],
   "source": [
    "def select_elites(states_batch, actions_batch, rewards_batch, percentile=50):\n",
    "    \"\"\"\n",
    "    Select states and actions from games that have rewards >= percentile\n",
    "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
    "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
    "    :param rewards_batch: list of rewards, rewards_batch[session_i]\n",
    "\n",
    "    :returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
    "\n",
    "    Please return elite states and actions in their original order \n",
    "    [i.e. sorted by session number and timestep within session]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    <YOUR CODE>\n",
    "    \n",
    "    return elite_states, elite_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6D6fsEJrg5U"
   },
   "source": [
    "# Training loop\n",
    "Generate sessions, select N best and fit to those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ICOgC6eJrg5V"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def show_progress(rewards_batch, log, percentile, reward_range=[-990, +10]):\n",
    "    \"\"\"\n",
    "    A convenience function that displays training progress. \n",
    "    No cool math here, just charts.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_reward = np.mean(rewards_batch)\n",
    "    threshold = np.percentile(rewards_batch, percentile)\n",
    "    log.append([mean_reward, threshold])\n",
    "\n",
    "    clear_output(True)\n",
    "    print(\"mean reward = %.3f, threshold=%.3f\" % (mean_reward, threshold))\n",
    "    plt.figure(figsize=[8, 4])\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(list(zip(*log))[0], label='Mean rewards')\n",
    "    plt.plot(list(zip(*log))[1], label='Reward thresholds')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(rewards_batch, range=reward_range)\n",
    "    plt.vlines([np.percentile(rewards_batch, percentile)],\n",
    "               [0], [100], label=\"percentile\", color='red')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mG34D0XErg5V"
   },
   "outputs": [],
   "source": [
    "n_sessions = 100\n",
    "percentile = 70\n",
    "log = []\n",
    "\n",
    "for i in range(100):\n",
    "    # generate new sessions\n",
    "    sessions = [ <YOUR CODE: generate a list of n_sessions new sessions> ]\n",
    "\n",
    "    states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
    "\n",
    "    elite_states, elite_actions = <YOUR CODE: select elite actions just like before>\n",
    "\n",
    "    <YOUR CODE: partial_fit agent to predict elite_actions(y) from elite_states(X)>\n",
    "\n",
    "    show_progress(rewards_batch, log, percentile, reward_range=[0, np.max(rewards_batch)])\n",
    "\n",
    "    if np.mean(rewards_batch) > 190:\n",
    "        print(\"You Win! You may stop training now via KeyboardInterrupt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpgRtQo9rg5W"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9mDksKerg5W"
   },
   "outputs": [],
   "source": [
    "# Record sessions\n",
    "\n",
    "import gym.wrappers\n",
    "\n",
    "with gym.wrappers.Monitor(gym.make(\"CartPole-v0\"), directory=\"videos\", force=True) as env_monitor:\n",
    "    sessions = [generate_session(env_monitor, agent) for _ in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mlSpMARWrg5W"
   },
   "outputs": [],
   "source": [
    "# Show video. This may not work in some setups. If it doesn't\n",
    "# work for you, you can download the videos and view them locally.\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import HTML\n",
    "\n",
    "video_names = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_names[-1]))  # You can also try other indices"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Q2_ToDo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
